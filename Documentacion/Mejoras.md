# Propuestas de Mejora y Redise√±o del Agente

Este documento propone mejoras basadas en an√°lisis de datos observados en el dashboard de observabilidad (IE12 - R√∫brica EFT).

## 1. An√°lisis de M√©tricas Actuales (Datos Observados)

### 1.1 Rendimiento y Latencia (IE2 - Dashboard)
**M√©tricas observadas** (promedio de 6 interacciones de prueba):
- **Latencia total media**: 3.42s (3422 ms)
- **Tiempo RAG**: ~0.8s (generaci√≥n embeddings + b√∫squeda)
- **Tiempo LLM**: ~2.6s (inferencia GPT-4o-mini)
- **Total tokens usados**: 983 tokens (promedio 164 tokens/consulta)

**Problemas identificados**:
1. ‚ùå Latencia >3s excede umbral recomendado de 2s para aplicaciones interactivas
2. ‚ùå 76% del tiempo se consume en llamada LLM (cuello de botella)
3. ‚ö†Ô∏è B√∫squeda h√≠brida (sem√°ntica + l√©xica) a√±ade 200ms vs b√∫squeda simple

### 1.2 Uso de Herramienta RAG (Decisi√≥n del Agente)
**M√©tricas observadas**:
- **100% de consultas usaron RAG** en pruebas con preguntas hospitalarias
- **0% LLM directo** (indica que la heur√≠stica de detecci√≥n funciona correctamente)

**Observaci√≥n positiva**: La estrategia de routing (detecci√≥n de keywords m√©dicas) es efectiva.

**Oportunidad de mejora**: A√±adir telemetr√≠a para casos edge donde LLM directo ser√≠a m√°s r√°pido (ej: "Hola", "Gracias").

### 1.3 Calidad de Respuestas (M√©tricas de Evaluaci√≥n)
**M√©tricas observadas** (promedio):
- **Faithfulness**: 7.2/10 (adherencia al contexto RAG)
- **Relevance**: 8.1/10 (pertinencia de la respuesta)
- **Context Precision**: 0.67 (67% de documentos recuperados fueron √∫tiles)

**Problemas identificados**:
1. ‚ö†Ô∏è Faithfulness <8 indica que el LLM ocasionalmente "inventa" informaci√≥n no presente en documentos
2. ‚ùå Context Precision 67% significa que 1 de cada 3 documentos recuperados es irrelevante (desperdicia tokens)

### 1.4 Estabilidad y Errores
**M√©tricas observadas**:
- **Tasa de error global**: 0% en pruebas controladas
- **Sin fallos cr√≠ticos** registrados

**Riesgo identificado**: No hay manejo de errores para:
- Timeout de API (>30s sin respuesta)
- Rate limiting de OpenAI (429 Too Many Requests)
- Fallo en generaci√≥n de embeddings

---

## 2. Propuestas de Mejora Priorizadas

### üî¥ **Prioridad 1: Cr√≠tico** (Impacto Alto + Esfuerzo Bajo)

#### Mejora 1.1: Cach√© de Embeddings
**Problema que resuelve**: Latencia de 800ms en generaci√≥n de embeddings por consulta repetida.

**Soluci√≥n propuesta**:
```python
from functools import lru_cache

@lru_cache(maxsize=100)
def get_query_embedding(query: str) -> np.ndarray:
    # Cachea embeddings de consultas frecuentes
    return client.embeddings.create(input=query, model="text-embedding-3-small")
```

**Impacto esperado**:
- ‚úÖ Reducci√≥n de latencia: 3.42s ‚Üí **2.6s** (24% mejora)
- ‚úÖ Ahorro de costos: ~40% menos llamadas a API de embeddings
- ‚úÖ Esfuerzo: **2 horas** de implementaci√≥n

**M√©trica de √©xito**: Latencia media <2.8s en dashboard (medible en Tab 3).

---

#### Mejora 1.2: Streaming de Respuestas LLM
**Problema que resuelve**: Usuario espera 2.6s sin feedback visual (mala UX).

**Soluci√≥n propuesta**:
```python
for chunk in client.chat.completions.create(
    model="gpt-4o-mini",
    messages=messages,
    stream=True  # Habilitar streaming
):
    st.write_stream(chunk.choices[0].delta.content)
```

**Impacto esperado**:
- ‚úÖ Percepci√≥n de latencia reducida (usuario ve texto generarse en tiempo real)
- ‚úÖ Tiempo hasta primer token: <500ms (vs 2.6s actuales)
- ‚úÖ Esfuerzo: **3 horas** (modificar `generate_response_with_metrics`)

**M√©trica de √©xito**: TTFT (Time To First Token) <500ms.

---

#### Mejora 1.3: Manejo de Errores con Retry Exponential Backoff
**Problema que resuelve**: Sin resiliencia ante fallos temporales de API.

**Soluci√≥n propuesta**:
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=10))
def call_llm_with_retry(messages):
    return client.chat.completions.create(model="gpt-4o-mini", messages=messages)
```

**Impacto esperado**:
- ‚úÖ Tasa de error: 0% ‚Üí **<0.1%** (99.9% disponibilidad)
- ‚úÖ Esfuerzo: **1 hora** (a√±adir dependencia `tenacity`)

**M√©trica de √©xito**: Proporci√≥n √âxito/Error >99% en dashboard.

---

### üü° **Prioridad 2: Importante** (Impacto Alto + Esfuerzo Medio)

#### Mejora 2.1: Reranking de Documentos Recuperados
**Problema que resuelve**: Context Precision solo 67% (33% de docs irrelevantes).

**Soluci√≥n propuesta**:
- Usar modelo de reranking (Cohere Rerank API o modelo local)
- Filtrar top-3 documentos despu√©s de b√∫squeda h√≠brida inicial (top-10)

**Impacto esperado**:
- ‚úÖ Context Precision: 67% ‚Üí **85%** (mejora de 27%)
- ‚úÖ Faithfulness: 7.2 ‚Üí **8.5** (menos alucinaciones)
- ‚úÖ Reducci√≥n de tokens: 164 ‚Üí **120** tokens/consulta (ahorro 27% en costos)
- ‚ùå Esfuerzo: **8 horas** (integraci√≥n + testing)

**M√©trica de √©xito**: Context Precision >80% en m√©tricas de calidad.

---

#### Mejora 2.2: Persistencia en SQLite (en vez de JSON)
**Problema que resuelve**: 
- Logs JSON crecen linealmente (2MB por 1000 interacciones)
- No permite consultas complejas ("mostrar errores del √∫ltimo mes")

**Soluci√≥n propuesta**:
```python
import sqlite3

conn = sqlite3.connect('data/atlas.db')
conn.execute('''
    CREATE TABLE interactions (
        id INTEGER PRIMARY KEY,
        timestamp TEXT,
        query TEXT,
        response TEXT,
        metrics JSON,
        error BOOLEAN
    )
''')
```

**Impacto esperado**:
- ‚úÖ Consultas anal√≠ticas: "SELECT AVG(latency) WHERE error=1" (imposible con JSON)
- ‚úÖ Tama√±o de almacenamiento: 2MB ‚Üí **0.5MB** (compresi√≥n nativa SQLite)
- ‚úÖ Escalabilidad: Soporta >10,000 interacciones sin degradaci√≥n
- ‚ùå Esfuerzo: **12 horas** (migraci√≥n + refactorizaci√≥n `_save_logs`)

**M√©trica de √©xito**: Dashboard puede mostrar gr√°ficos de √∫ltimos 30 d√≠as sin lag.

---

#### Mejora 2.3: Evaluaci√≥n Autom√°tica con Dataset de Referencia
**Problema que resuelve**: M√©tricas de calidad (faithfulness, relevance) solo se calculan en tiempo real (no hay baseline).

**Soluci√≥n propuesta**:
- Crear `data/eval_dataset.json` con 20 pares pregunta-respuesta gold-standard
- Ejecutar evaluaci√≥n batch semanal y comparar vs baseline

**Impacto esperado**:
- ‚úÖ Detecci√≥n temprana de regresi√≥n (si faithfulness baja de 7.2 ‚Üí 6.0)
- ‚úÖ Benchmark reproducible para defensa acad√©mica
- ‚ùå Esfuerzo: **6 horas** (crear dataset + script de evaluaci√≥n)

**M√©trica de √©xito**: Notebook `logs_analysis.ipynb` con comparaci√≥n semanal de m√©tricas.

---

### üü¢ **Prioridad 3: Deseable** (Impacto Medio + Esfuerzo Alto)

#### Mejora 3.1: Integraci√≥n de Fuente Externa Real (API FHIR)
**Problema que resuelve**: Solo fuentes internas est√°ticas (documentos predef inidos).

**Soluci√≥n propuesta**:
- Integrar API FHIR del sistema hospitalario (ej: disponibilidad de camas, turnos m√©dicos)
- Actualizar documentos RAG autom√°ticamente cada 1 hora

**Impacto esperado**:
- ‚úÖ Informaci√≥n siempre actualizada (vs docs est√°ticos que envejecen)
- ‚úÖ Cumple IE2 al 100% (fuentes externas reales)
- ‚ùå Esfuerzo: **20 horas** (coordinaci√≥n con TI hospitalaria + integraci√≥n)

**M√©trica de √©xito**: Dashboard muestra timestamp de √∫ltima actualizaci√≥n de datos.

---

#### Mejora 3.2: Multimodal (Soporte para Im√°genes M√©dicas)
**Problema que resuelve**: Solo texto (no puede interpretar ex√°menes, mapas hospitalarios).

**Soluci√≥n propuesta**:
- Usar GPT-4o (multimodal) en vez de GPT-4o-mini
- Permitir subir im√°genes (radiograf√≠as, mapas) en chat

**Impacto esperado**:
- ‚úÖ Casos de uso ampliados: "Explica esta radiograf√≠a", "¬øC√≥mo llego al pab. 3?"
- ‚ùå Costo: 10x m√°s caro ($5/1M tokens vs $0.15/1M)
- ‚ùå Esfuerzo: **15 horas** (cambio de modelo + UI para upload de im√°genes)

**M√©trica de √©xito**: Dashboard muestra m√©trica "Consultas con imagen" vs "Solo texto".

---

#### Mejora 3.3: Despliegue en Azure con Monitoreo (Application Insights)
**Problema que resuelve**: Streamlit Cloud tiene limitaciones (sin auto-scaling, logs efimeros).

**Soluci√≥n propuesta**:
- Dockerizar aplicaci√≥n + desplegar en Azure Container Apps
- Integrar Application Insights para telemetr√≠a avanzada (trazas distribuidas, alertas)

**Impacto esperado**:
- ‚úÖ Disponibilidad: 99.9% SLA (vs 99% de Streamlit Cloud)
- ‚úÖ Auto-scaling: Soporta >100 usuarios simult√°neos
- ‚úÖ Alertas proactivas: Email si latencia >5s o error rate >1%
- ‚ùå Costo: $50-100/mes (vs gratis en Streamlit Cloud)
- ‚ùå Esfuerzo: **30 horas** (DevOps + configuraci√≥n)

**M√©trica de √©xito**: Uptime >99.9% medido en Azure Portal.

---

## 3. Roadmap de Implementaci√≥n
### Sprint 1 (Semana 1-2) - Post-Entrega EFT
- [ ] Mejora 1.1: Cach√© de embeddings
- [ ] Mejora 1.2: Streaming de respuestas
- [ ] Mejora 1.3: Retry con backoff exponencial

**Objetivo**: Reducir latencia a <2.8s y disponibilidad >99%.

### Sprint 2 (Semana 3-4)
- [ ] Mejora 2.1: Reranking de documentos
- [ ] Mejora 2.3: Dataset de evaluaci√≥n autom√°tica

**Objetivo**: Faithfulness >8.0 y Context Precision >80%.

### Sprint 3 (Mes 2)
- [ ] Mejora 2.2: Migraci√≥n a SQLite
- [ ] Mejora 3.1: Integraci√≥n API FHIR (si hay acceso)

**Objetivo**: Escalabilidad para >1000 interacciones.

### Fase de Producci√≥n (Mes 3-6)
- [ ] Mejora 3.3: Despliegue en Azure
- [ ] Mejora 3.2: Soporte multimodal (opcional)
- [ ] Auditor√≠a de seguridad externa

---

## 4. An√°lisis de Costo-Beneficio

| Mejora | Impacto (1-10) | Esfuerzo (horas) | ROI | Prioridad |
|--------|----------------|------------------|-----|----------|
| 1.1 Cach√© embeddings | 8 | 2 | üü¢ Alto | 1 |
| 1.2 Streaming | 7 | 3 | üü¢ Alto | 1 |
| 1.3 Retry + backoff | 9 | 1 | üü¢ Muy Alto | 1 |
| 2.1 Reranking | 8 | 8 | üü° Medio | 2 |
| 2.2 SQLite | 7 | 12 | üü° Medio | 2 |
| 2.3 Eval autom√°tica | 6 | 6 | üü° Medio | 2 |
| 3.1 API FHIR | 9 | 20 | üü† Bajo | 3 |
| 3.2 Multimodal | 6 | 15 | üü† Bajo | 3 |
| 3.3 Azure deploy | 8 | 30 | üü† Bajo | 3 |

---

## 5. Sostenibilidad y Escalabilidad

### Sostenibilidad (Largo Plazo)
**Proyecci√≥n de costos** (1000 usuarios/mes):
- **Actual**: $10/mes (solo API calls)
- **Con mejoras Fase 1-2**: $8/mes (cach√© reduce 20% llamadas)
- **Producci√≥n (Fase 3)**: $150/mes (Azure hosting $100 + API $50)

**Costo por interacci√≥n**:
- Actual: $0.0001 (10 centavos por 1000 consultas)
- Target: $0.00008 (mejoras 1.1 + 2.1)

### Escalabilidad (M√°s Usuarios)
**Capacidad actual** (Streamlit Cloud):
- M√°x usuarios simult√°neos: ~20
- Latencia con 50 usuarios: >10s (inaceptable)

**Capacidad con mejoras**:
- Mejora 2.2 (SQLite): Soporta 100 usuarios
- Mejora 3.3 (Azure + auto-scaling): Soporta 1000+ usuarios

---

## 6. Referencias para Implementaci√≥n

- Cach√© LRU: https://docs.python.org/3/library/functools.html#functools.lru_cache
- Streaming Streamlit: https://docs.streamlit.io/library/api-reference/write-magic/st.write_stream
- Tenacity (retry): https://tenacity.readthedocs.io/
- Cohere Rerank: https://docs.cohere.com/docs/reranking
- SQLite con Python: https://docs.python.org/3/library/sqlite3.html
- Azure Container Apps: https://learn.microsoft.com/en-us/azure/container-apps/

---

**Conclusi√≥n**: Las mejoras priorizadas se basan directamente en m√©tricas observadas del dashboard. Implementar Fase 1 (Mejoras 1.1-1.3) reducir√≠a latencia en 24% y aumentar√≠a disponibilidad a 99.9%, mejorando significativamente UX y confiabilidad del sistema.
